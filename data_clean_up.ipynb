{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.core.display import display, HTML\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "import diagnostic_plots\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to pick for efficiency\n",
    "\n",
    "\n",
    "\n",
    "filename_berkely = '/Users/xzhou/github/project_files/project_luther/professor_data_berkely_add_features.pkl' #3986 records\n",
    "filename_nyu = '/Users/xzhou/github/project_files/project_luther/professor_data_nyu_add_features.pkl' #5607 records\n",
    "filename_uf = '/Users/xzhou/github/project_files/project_luther/professor_data_uf_add_features.pkl' #5307 records\n",
    "\n",
    "df_berkely=pd.read_pickle(filename_berkely)\n",
    "df_nyu=pd.read_pickle(filename_nyu)\n",
    "df_uf=pd.read_pickle(filename_uf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3986, 30)\n",
      "(5607, 30)\n",
      "(5306, 30)\n"
     ]
    }
   ],
   "source": [
    "print(df_berkely.shape)\n",
    "print(df_nyu.shape)\n",
    "print(df_uf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14899, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define key for each section. This would be used for future references. \n",
    "dfs=pd.concat([df_berkely, df_nyu, df_uf],keys=['berkely', 'nyu', 'uf'])\n",
    "dfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Level of difficulty</th>\n",
       "      <th>Total reviews</th>\n",
       "      <th>Student size</th>\n",
       "      <th>Type_public</th>\n",
       "      <th>Type_private</th>\n",
       "      <th>Region_west</th>\n",
       "      <th>Region_east</th>\n",
       "      <th>Region_south</th>\n",
       "      <th>...</th>\n",
       "      <th>Hilarious</th>\n",
       "      <th>Inspirational</th>\n",
       "      <th>Lecture heavy</th>\n",
       "      <th>Lots of homework</th>\n",
       "      <th>Participation matters</th>\n",
       "      <th>Respected</th>\n",
       "      <th>Skip class? you won't pass.</th>\n",
       "      <th>So many papers</th>\n",
       "      <th>Test heavy</th>\n",
       "      <th>Tough grader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">uf</th>\n",
       "      <th>5301</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>52367</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>52367</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303</th>\n",
       "      <td>Tina D'Allesandro</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52367</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5304</th>\n",
       "      <td>Kay Leary</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52367</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5305</th>\n",
       "      <td>Lisa Domenico</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52367</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name  Rating  Level of difficulty  Total reviews  \\\n",
       "uf 5301                        0.0                  2.5              0   \n",
       "   5302                        0.0                  2.5              0   \n",
       "   5303  Tina D'Allesandro     4.0                  3.0              1   \n",
       "   5304          Kay Leary     5.0                  3.0              1   \n",
       "   5305      Lisa Domenico     4.0                  5.0              1   \n",
       "\n",
       "         Student size  Type_public  Type_private  Region_west  Region_east  \\\n",
       "uf 5301         52367            1             0            0            0   \n",
       "   5302         52367            1             0            0            0   \n",
       "   5303         52367            1             0            0            0   \n",
       "   5304         52367            1             0            0            0   \n",
       "   5305         52367            1             0            0            0   \n",
       "\n",
       "         Region_south      ...       Hilarious  Inspirational  Lecture heavy  \\\n",
       "uf 5301             1      ...             0.0            0.0            0.0   \n",
       "   5302             1      ...             0.0            0.0            0.0   \n",
       "   5303             1      ...             0.0            0.0            0.0   \n",
       "   5304             1      ...             0.0            0.0            0.0   \n",
       "   5305             1      ...             0.0            0.0            0.0   \n",
       "\n",
       "         Lots of homework  Participation matters  Respected  \\\n",
       "uf 5301               0.0                   0.00        0.0   \n",
       "   5302               0.0                   0.00        0.0   \n",
       "   5303               0.0                   0.33        0.0   \n",
       "   5304               0.0                   0.00        0.0   \n",
       "   5305               0.0                   0.33        0.0   \n",
       "\n",
       "         Skip class? you won't pass.  So many papers  Test heavy  Tough grader  \n",
       "uf 5301                          0.0             0.0         0.0           0.0  \n",
       "   5302                          0.0             0.0         0.0           0.0  \n",
       "   5303                          0.0             0.0         0.0           0.0  \n",
       "   5304                          0.0             0.0         0.0           0.0  \n",
       "   5305                          0.0             0.0         0.0           0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# noted records with no professor name\n",
    "dfs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Level of difficulty</th>\n",
       "      <th>Total reviews</th>\n",
       "      <th>Student size</th>\n",
       "      <th>Type_public</th>\n",
       "      <th>Type_private</th>\n",
       "      <th>Region_west</th>\n",
       "      <th>Region_east</th>\n",
       "      <th>Region_south</th>\n",
       "      <th>...</th>\n",
       "      <th>Hilarious</th>\n",
       "      <th>Inspirational</th>\n",
       "      <th>Lecture heavy</th>\n",
       "      <th>Lots of homework</th>\n",
       "      <th>Participation matters</th>\n",
       "      <th>Respected</th>\n",
       "      <th>Skip class? you won't pass.</th>\n",
       "      <th>So many papers</th>\n",
       "      <th>Test heavy</th>\n",
       "      <th>Tough grader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">berkely</th>\n",
       "      <th>244</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>41910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>41910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>41910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>41910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>41910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name  Rating  Level of difficulty  Total reviews  Student size  \\\n",
       "berkely 244          0.0                  2.5              0         41910   \n",
       "        274          0.0                  2.5              0         41910   \n",
       "        376          0.0                  2.5              0         41910   \n",
       "        416          0.0                  2.5              0         41910   \n",
       "        478          0.0                  2.5              0         41910   \n",
       "\n",
       "             Type_public  Type_private  Region_west  Region_east  \\\n",
       "berkely 244            1             0            1            0   \n",
       "        274            1             0            1            0   \n",
       "        376            1             0            1            0   \n",
       "        416            1             0            1            0   \n",
       "        478            1             0            1            0   \n",
       "\n",
       "             Region_south      ...       Hilarious  Inspirational  \\\n",
       "berkely 244             0      ...             0.0            0.0   \n",
       "        274             0      ...             0.0            0.0   \n",
       "        376             0      ...             0.0            0.0   \n",
       "        416             0      ...             0.0            0.0   \n",
       "        478             0      ...             0.0            0.0   \n",
       "\n",
       "             Lecture heavy  Lots of homework  Participation matters  \\\n",
       "berkely 244            0.0               0.0                    0.0   \n",
       "        274            0.0               0.0                    0.0   \n",
       "        376            0.0               0.0                    0.0   \n",
       "        416            0.0               0.0                    0.0   \n",
       "        478            0.0               0.0                    0.0   \n",
       "\n",
       "             Respected  Skip class? you won't pass.  So many papers  \\\n",
       "berkely 244        0.0                          0.0             0.0   \n",
       "        274        0.0                          0.0             0.0   \n",
       "        376        0.0                          0.0             0.0   \n",
       "        416        0.0                          0.0             0.0   \n",
       "        478        0.0                          0.0             0.0   \n",
       "\n",
       "             Test heavy  Tough grader  \n",
       "berkely 244         0.0           0.0  \n",
       "        274         0.0           0.0  \n",
       "        376         0.0           0.0  \n",
       "        416         0.0           0.0  \n",
       "        478         0.0           0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[dfs.Name==\"\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13238, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove records that don't have professor names\n",
    "dfs_smaller=dfs[dfs.Name!=\"\"]\n",
    "dfs_smaller.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_smaller=dfs_smaller.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Rating', 'Level of difficulty', 'Total reviews',\n",
       "       'Student size', 'Type_public', 'Type_private', 'Region_west',\n",
       "       'Region_east', 'Region_south', 'Accessible outside class',\n",
       "       'Amazing lectures', 'Beware of pop quizzes', 'Caring',\n",
       "       'Clear grading criteria', 'Extra credit', 'Get ready to read',\n",
       "       'Gives good feedback', 'Graded by few things', 'Group projects',\n",
       "       'Hilarious', 'Inspirational', 'Lecture heavy', 'Lots of homework',\n",
       "       'Participation matters', 'Respected', 'Skip class? you won't pass.',\n",
       "       'So many papers', 'Test heavy', 'Tough grader'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_smaller.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Level of difficulty</th>\n",
       "      <th>Total reviews</th>\n",
       "      <th>Student size</th>\n",
       "      <th>Type_public</th>\n",
       "      <th>Type_private</th>\n",
       "      <th>Region_west</th>\n",
       "      <th>Region_east</th>\n",
       "      <th>Region_south</th>\n",
       "      <th>...</th>\n",
       "      <th>Hilarious</th>\n",
       "      <th>Inspirational</th>\n",
       "      <th>Lecture heavy</th>\n",
       "      <th>Lots of homework</th>\n",
       "      <th>Participation matters</th>\n",
       "      <th>Respected</th>\n",
       "      <th>Skip class? you won't pass.</th>\n",
       "      <th>So many papers</th>\n",
       "      <th>Test heavy</th>\n",
       "      <th>Tough grader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">berkely</th>\n",
       "      <th>1</th>\n",
       "      <td>Chris Dolder</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>9</td>\n",
       "      <td>41910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob Calonico</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>29</td>\n",
       "      <td>41910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mary Kelsey</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>63</td>\n",
       "      <td>41910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>John Searle</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>47</td>\n",
       "      <td>41910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>William Hanks</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>25</td>\n",
       "      <td>41910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name  Rating  Level of difficulty  Total reviews  \\\n",
       "berkely 1   Chris Dolder     4.8                  3.9              9   \n",
       "        2   Bob Calonico     4.7                  1.6             29   \n",
       "        4    Mary Kelsey     4.6                  1.6             63   \n",
       "        5    John Searle     3.6                  3.1             47   \n",
       "        8  William Hanks     4.4                  2.2             25   \n",
       "\n",
       "           Student size  Type_public  Type_private  Region_west  Region_east  \\\n",
       "berkely 1         41910            1             0            1            0   \n",
       "        2         41910            1             0            1            0   \n",
       "        4         41910            1             0            1            0   \n",
       "        5         41910            1             0            1            0   \n",
       "        8         41910            1             0            1            0   \n",
       "\n",
       "           Region_south      ...       Hilarious  Inspirational  \\\n",
       "berkely 1             0      ...            0.00           0.50   \n",
       "        2             0      ...            0.26           0.32   \n",
       "        4             0      ...            0.00           0.08   \n",
       "        5             0      ...            0.21           0.07   \n",
       "        8             0      ...            0.00           0.33   \n",
       "\n",
       "           Lecture heavy  Lots of homework  Participation matters  Respected  \\\n",
       "berkely 1           0.00               0.0                   0.00       0.00   \n",
       "        2           0.00               0.0                   0.00       0.11   \n",
       "        4           0.04               0.0                   0.08       0.12   \n",
       "        5           0.00               0.0                   0.00       0.21   \n",
       "        8           0.00               0.0                   0.00       0.00   \n",
       "\n",
       "           Skip class? you won't pass.  So many papers  Test heavy  \\\n",
       "berkely 1                         0.00             0.0         0.0   \n",
       "        2                         0.00             0.0         0.0   \n",
       "        4                         0.04             0.0         0.0   \n",
       "        5                         0.00             0.0         0.0   \n",
       "        8                         0.33             0.0         0.0   \n",
       "\n",
       "           Tough grader  \n",
       "berkely 1          0.00  \n",
       "        2          0.00  \n",
       "        4          0.04  \n",
       "        5          0.07  \n",
       "        8          0.00  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear out records without tags\n",
    "dfs_smaller.insert(5,'Total score for Tags', dfs_smaller.sum(axis=1)-dfs_smaller['Rating']-dfs_smaller['Level of difficulty']-dfs_smaller['Total reviews']-dfs_smaller['Student size']-dfs_smaller['Type_public']-dfs_smaller['Type_private']-dfs_smaller['Region_west']-dfs_smaller['Region_east']-dfs_smaller['Region_south'])\n",
    "dfs_clean=dfs_smaller[dfs_smaller['Total score for Tags']>0.9]\n",
    "dfs_clean=dfs_clean.drop(['Total score for Tags'], 1)\n",
    "dfs_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on professor with meaningful number of reviews\n",
    "\n",
    "dfs_clean=dfs_clean[dfs_clean['Total reviews']>=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4798, 30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Rating', 'Level of difficulty', 'Total reviews',\n",
       "       'Student size', 'Type_public', 'Type_private', 'Region_west',\n",
       "       'Region_east', 'Region_south', 'Accessible outside class',\n",
       "       'Amazing lectures', 'Beware of pop quizzes', 'Caring',\n",
       "       'Clear grading criteria', 'Extra credit', 'Get ready to read',\n",
       "       'Gives good feedback', 'Graded by few things', 'Group projects',\n",
       "       'Hilarious', 'Inspirational', 'Lecture heavy', 'Lots of homework',\n",
       "       'Participation matters', 'Respected', 'Skip class? you won't pass.',\n",
       "       'So many papers', 'Test heavy', 'Tough grader'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Level of difficulty</th>\n",
       "      <th>Total reviews</th>\n",
       "      <th>Student size</th>\n",
       "      <th>Type_public</th>\n",
       "      <th>Type_private</th>\n",
       "      <th>Region_west</th>\n",
       "      <th>Region_east</th>\n",
       "      <th>Region_south</th>\n",
       "      <th>Accessible outside class</th>\n",
       "      <th>...</th>\n",
       "      <th>Hilarious</th>\n",
       "      <th>Inspirational</th>\n",
       "      <th>Lecture heavy</th>\n",
       "      <th>Lots of homework</th>\n",
       "      <th>Participation matters</th>\n",
       "      <th>Respected</th>\n",
       "      <th>Skip class? you won't pass.</th>\n",
       "      <th>So many papers</th>\n",
       "      <th>Test heavy</th>\n",
       "      <th>Tough grader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "      <td>4798.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.808629</td>\n",
       "      <td>3.011192</td>\n",
       "      <td>17.503126</td>\n",
       "      <td>52447.240725</td>\n",
       "      <td>0.574198</td>\n",
       "      <td>0.425802</td>\n",
       "      <td>0.264902</td>\n",
       "      <td>0.425802</td>\n",
       "      <td>0.309296</td>\n",
       "      <td>0.036711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046765</td>\n",
       "      <td>0.063287</td>\n",
       "      <td>0.052209</td>\n",
       "      <td>0.047203</td>\n",
       "      <td>0.062805</td>\n",
       "      <td>0.079454</td>\n",
       "      <td>0.058343</td>\n",
       "      <td>0.012386</td>\n",
       "      <td>0.017614</td>\n",
       "      <td>0.087136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.878436</td>\n",
       "      <td>0.752749</td>\n",
       "      <td>26.916727</td>\n",
       "      <td>6931.836761</td>\n",
       "      <td>0.494516</td>\n",
       "      <td>0.494516</td>\n",
       "      <td>0.441327</td>\n",
       "      <td>0.494516</td>\n",
       "      <td>0.462251</td>\n",
       "      <td>0.076697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097551</td>\n",
       "      <td>0.106778</td>\n",
       "      <td>0.112295</td>\n",
       "      <td>0.098289</td>\n",
       "      <td>0.109910</td>\n",
       "      <td>0.115346</td>\n",
       "      <td>0.104283</td>\n",
       "      <td>0.050403</td>\n",
       "      <td>0.056999</td>\n",
       "      <td>0.145612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>41910.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.300000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>41910.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>52367.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59061.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>59061.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rating  Level of difficulty  Total reviews  Student size  \\\n",
       "count  4798.000000          4798.000000    4798.000000   4798.000000   \n",
       "mean      3.808629             3.011192      17.503126  52447.240725   \n",
       "std       0.878436             0.752749      26.916727   6931.836761   \n",
       "min       1.000000             1.000000       3.000000  41910.000000   \n",
       "25%       3.300000             2.500000       5.000000  41910.000000   \n",
       "50%       4.000000             3.000000      10.000000  52367.000000   \n",
       "75%       4.500000             3.500000      20.000000  59061.000000   \n",
       "max       5.000000             5.000000     507.000000  59061.000000   \n",
       "\n",
       "       Type_public  Type_private  Region_west  Region_east  Region_south  \\\n",
       "count  4798.000000   4798.000000  4798.000000  4798.000000   4798.000000   \n",
       "mean      0.574198      0.425802     0.264902     0.425802      0.309296   \n",
       "std       0.494516      0.494516     0.441327     0.494516      0.462251   \n",
       "min       0.000000      0.000000     0.000000     0.000000      0.000000   \n",
       "25%       0.000000      0.000000     0.000000     0.000000      0.000000   \n",
       "50%       1.000000      0.000000     0.000000     0.000000      0.000000   \n",
       "75%       1.000000      1.000000     1.000000     1.000000      1.000000   \n",
       "max       1.000000      1.000000     1.000000     1.000000      1.000000   \n",
       "\n",
       "       Accessible outside class      ...         Hilarious  Inspirational  \\\n",
       "count               4798.000000      ...       4798.000000    4798.000000   \n",
       "mean                   0.036711      ...          0.046765       0.063287   \n",
       "std                    0.076697      ...          0.097551       0.106778   \n",
       "min                    0.000000      ...          0.000000       0.000000   \n",
       "25%                    0.000000      ...          0.000000       0.000000   \n",
       "50%                    0.000000      ...          0.000000       0.000000   \n",
       "75%                    0.040000      ...          0.050000       0.100000   \n",
       "max                    1.000000      ...          1.000000       1.000000   \n",
       "\n",
       "       Lecture heavy  Lots of homework  Participation matters    Respected  \\\n",
       "count    4798.000000       4798.000000            4798.000000  4798.000000   \n",
       "mean        0.052209          0.047203               0.062805     0.079454   \n",
       "std         0.112295          0.098289               0.109910     0.115346   \n",
       "min         0.000000          0.000000               0.000000     0.000000   \n",
       "25%         0.000000          0.000000               0.000000     0.000000   \n",
       "50%         0.000000          0.000000               0.000000     0.000000   \n",
       "75%         0.067500          0.050000               0.100000     0.130000   \n",
       "max         1.000000          1.000000               1.000000     1.000000   \n",
       "\n",
       "       Skip class? you won't pass.  So many papers   Test heavy  Tough grader  \n",
       "count                  4798.000000     4798.000000  4798.000000   4798.000000  \n",
       "mean                      0.058343        0.012386     0.017614      0.087136  \n",
       "std                       0.104283        0.050403     0.056999      0.145612  \n",
       "min                       0.000000        0.000000     0.000000      0.000000  \n",
       "25%                       0.000000        0.000000     0.000000      0.000000  \n",
       "50%                       0.000000        0.000000     0.000000      0.000000  \n",
       "75%                       0.090000        0.000000     0.000000      0.140000  \n",
       "max                       1.000000        0.500000     1.000000      1.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c267954e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs_clean['Rating'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Level of difficulty</th>\n",
       "      <th>Total reviews</th>\n",
       "      <th>Student size</th>\n",
       "      <th>Type_public</th>\n",
       "      <th>Type_private</th>\n",
       "      <th>Region_west</th>\n",
       "      <th>Region_east</th>\n",
       "      <th>Region_south</th>\n",
       "      <th>Accessible outside class</th>\n",
       "      <th>...</th>\n",
       "      <th>Hilarious</th>\n",
       "      <th>Inspirational</th>\n",
       "      <th>Lecture heavy</th>\n",
       "      <th>Lots of homework</th>\n",
       "      <th>Participation matters</th>\n",
       "      <th>Respected</th>\n",
       "      <th>Skip class? you won't pass.</th>\n",
       "      <th>So many papers</th>\n",
       "      <th>Test heavy</th>\n",
       "      <th>Tough grader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">berkely</th>\n",
       "      <th>1</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>41910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>41910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>41910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.850148</td>\n",
       "      <td>41910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>41910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rating  Level of difficulty  Total reviews  Student size  \\\n",
       "berkely 1     4.8                  3.9       2.197225         41910   \n",
       "        2     4.7                  1.6       3.367296         41910   \n",
       "        4     4.6                  1.6       4.143135         41910   \n",
       "        5     3.6                  3.1       3.850148         41910   \n",
       "        8     4.4                  2.2       3.218876         41910   \n",
       "\n",
       "           Type_public  Type_private  Region_west  Region_east  Region_south  \\\n",
       "berkely 1            1             0            1            0             0   \n",
       "        2            1             0            1            0             0   \n",
       "        4            1             0            1            0             0   \n",
       "        5            1             0            1            0             0   \n",
       "        8            1             0            1            0             0   \n",
       "\n",
       "           Accessible outside class      ...       Hilarious  Inspirational  \\\n",
       "berkely 1                      0.00      ...            0.00           0.50   \n",
       "        2                      0.05      ...            0.26           0.32   \n",
       "        4                      0.04      ...            0.00           0.08   \n",
       "        5                      0.00      ...            0.21           0.07   \n",
       "        8                      0.00      ...            0.00           0.33   \n",
       "\n",
       "           Lecture heavy  Lots of homework  Participation matters  Respected  \\\n",
       "berkely 1           0.00               0.0                   0.00       0.00   \n",
       "        2           0.00               0.0                   0.00       0.11   \n",
       "        4           0.04               0.0                   0.08       0.12   \n",
       "        5           0.00               0.0                   0.00       0.21   \n",
       "        8           0.00               0.0                   0.00       0.00   \n",
       "\n",
       "           Skip class? you won't pass.  So many papers  Test heavy  \\\n",
       "berkely 1                         0.00             0.0         0.0   \n",
       "        2                         0.00             0.0         0.0   \n",
       "        4                         0.04             0.0         0.0   \n",
       "        5                         0.00             0.0         0.0   \n",
       "        8                         0.33             0.0         0.0   \n",
       "\n",
       "           Tough grader  \n",
       "berkely 1          0.00  \n",
       "        2          0.00  \n",
       "        4          0.04  \n",
       "        5          0.07  \n",
       "        8          0.00  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform transformation of Total reviews and drop unnecessary fields\n",
    "dfs_clean['Total reviews']=np.log(dfs_clean['Total reviews'])\n",
    "dfs_clean=dfs_clean.drop('Name', axis=1)\n",
    "dfs_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(dfs_clean,  size = 2, aspect=1.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform training and test sets split:\n",
    "\n",
    "def tt_split(df, y_column, test_size):\n",
    "    X=df.drop(y_column, 1)\n",
    "    y=df[y_column]\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.464</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.450</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   33.62</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 20 Jul 2018</td> <th>  Prob (F-statistic):</th> <td>7.27e-109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:56:56</td>     <th>  Log-Likelihood:    </th> <td> -949.69</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   959</td>      <th>  AIC:               </th> <td>   1949.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   934</td>      <th>  BIC:               </th> <td>   2071.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    24</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                       <td>    0.2528</td> <td>    0.061</td> <td>    4.158</td> <td> 0.000</td> <td>    0.134</td> <td>    0.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Level of difficulty</th>         <td>   -0.2547</td> <td>    0.033</td> <td>   -7.682</td> <td> 0.000</td> <td>   -0.320</td> <td>   -0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total reviews</th>               <td>   -0.0155</td> <td>    0.024</td> <td>   -0.637</td> <td> 0.524</td> <td>   -0.063</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Student size</th>                <td>    0.0001</td> <td>  3.3e-05</td> <td>    4.279</td> <td> 0.000</td> <td> 7.65e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_public</th>                 <td>    0.6302</td> <td>    0.148</td> <td>    4.269</td> <td> 0.000</td> <td>    0.341</td> <td>    0.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_private</th>                <td>   -0.3773</td> <td>    0.087</td> <td>   -4.328</td> <td> 0.000</td> <td>   -0.548</td> <td>   -0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_west</th>                 <td>    1.0246</td> <td>    0.249</td> <td>    4.108</td> <td> 0.000</td> <td>    0.535</td> <td>    1.514</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_east</th>                 <td>   -0.3773</td> <td>    0.087</td> <td>   -4.328</td> <td> 0.000</td> <td>   -0.548</td> <td>   -0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_south</th>                <td>   -0.3944</td> <td>    0.104</td> <td>   -3.779</td> <td> 0.000</td> <td>   -0.599</td> <td>   -0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Accessible outside class</th>    <td>   -2.1003</td> <td>    1.865</td> <td>   -1.126</td> <td> 0.260</td> <td>   -5.761</td> <td>    1.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Amazing lectures</th>            <td>   -1.9157</td> <td>    1.852</td> <td>   -1.034</td> <td> 0.301</td> <td>   -5.550</td> <td>    1.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Beware of pop quizzes</th>       <td>   -3.3974</td> <td>    1.917</td> <td>   -1.772</td> <td> 0.077</td> <td>   -7.159</td> <td>    0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Caring</th>                      <td>   -2.6671</td> <td>    1.857</td> <td>   -1.437</td> <td> 0.151</td> <td>   -6.311</td> <td>    0.976</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clear grading criteria</th>      <td>   -3.3657</td> <td>    1.856</td> <td>   -1.814</td> <td> 0.070</td> <td>   -7.008</td> <td>    0.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Extra credit</th>                <td>   -2.9029</td> <td>    1.860</td> <td>   -1.561</td> <td> 0.119</td> <td>   -6.553</td> <td>    0.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Get ready to read</th>           <td>   -3.7070</td> <td>    1.852</td> <td>   -2.002</td> <td> 0.046</td> <td>   -7.342</td> <td>   -0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gives good feedback</th>         <td>   -2.8392</td> <td>    1.859</td> <td>   -1.528</td> <td> 0.127</td> <td>   -6.487</td> <td>    0.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Graded by few things</th>        <td>   -4.2048</td> <td>    1.868</td> <td>   -2.251</td> <td> 0.025</td> <td>   -7.870</td> <td>   -0.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Group projects</th>              <td>   -4.6637</td> <td>    1.867</td> <td>   -2.497</td> <td> 0.013</td> <td>   -8.329</td> <td>   -0.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hilarious</th>                   <td>   -2.8966</td> <td>    1.849</td> <td>   -1.567</td> <td> 0.117</td> <td>   -6.525</td> <td>    0.731</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Inspirational</th>               <td>   -2.7624</td> <td>    1.857</td> <td>   -1.487</td> <td> 0.137</td> <td>   -6.407</td> <td>    0.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lecture heavy</th>               <td>   -4.0163</td> <td>    1.853</td> <td>   -2.168</td> <td> 0.030</td> <td>   -7.652</td> <td>   -0.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lots of homework</th>            <td>   -4.0522</td> <td>    1.862</td> <td>   -2.177</td> <td> 0.030</td> <td>   -7.705</td> <td>   -0.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Participation matters</th>       <td>   -2.8363</td> <td>    1.864</td> <td>   -1.522</td> <td> 0.128</td> <td>   -6.494</td> <td>    0.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Respected</th>                   <td>   -2.2358</td> <td>    1.840</td> <td>   -1.215</td> <td> 0.225</td> <td>   -5.848</td> <td>    1.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skip class? you won't pass.</th> <td>   -3.5508</td> <td>    1.860</td> <td>   -1.909</td> <td> 0.057</td> <td>   -7.202</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>So many papers</th>              <td>   -5.7155</td> <td>    1.926</td> <td>   -2.967</td> <td> 0.003</td> <td>   -9.496</td> <td>   -1.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Test heavy</th>                  <td>   -5.0964</td> <td>    1.884</td> <td>   -2.705</td> <td> 0.007</td> <td>   -8.794</td> <td>   -1.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tough grader</th>                <td>   -4.5976</td> <td>    1.846</td> <td>   -2.491</td> <td> 0.013</td> <td>   -8.220</td> <td>   -0.975</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>61.682</td> <th>  Durbin-Watson:     </th> <td>   1.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  73.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.615</td> <th>  Prob(JB):          </th> <td>9.24e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.579</td> <th>  Cond. No.          </th> <td>3.08e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.85e-23. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.464\n",
       "Model:                            OLS   Adj. R-squared:                  0.450\n",
       "Method:                 Least Squares   F-statistic:                     33.62\n",
       "Date:                Fri, 20 Jul 2018   Prob (F-statistic):          7.27e-109\n",
       "Time:                        01:56:56   Log-Likelihood:                -949.69\n",
       "No. Observations:                 959   AIC:                             1949.\n",
       "Df Residuals:                     934   BIC:                             2071.\n",
       "Df Model:                          24                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "const                           0.2528      0.061      4.158      0.000       0.134       0.372\n",
       "Level of difficulty            -0.2547      0.033     -7.682      0.000      -0.320      -0.190\n",
       "Total reviews                  -0.0155      0.024     -0.637      0.524      -0.063       0.032\n",
       "Student size                    0.0001    3.3e-05      4.279      0.000    7.65e-05       0.000\n",
       "Type_public                     0.6302      0.148      4.269      0.000       0.341       0.920\n",
       "Type_private                   -0.3773      0.087     -4.328      0.000      -0.548      -0.206\n",
       "Region_west                     1.0246      0.249      4.108      0.000       0.535       1.514\n",
       "Region_east                    -0.3773      0.087     -4.328      0.000      -0.548      -0.206\n",
       "Region_south                   -0.3944      0.104     -3.779      0.000      -0.599      -0.190\n",
       "Accessible outside class       -2.1003      1.865     -1.126      0.260      -5.761       1.560\n",
       "Amazing lectures               -1.9157      1.852     -1.034      0.301      -5.550       1.718\n",
       "Beware of pop quizzes          -3.3974      1.917     -1.772      0.077      -7.159       0.365\n",
       "Caring                         -2.6671      1.857     -1.437      0.151      -6.311       0.976\n",
       "Clear grading criteria         -3.3657      1.856     -1.814      0.070      -7.008       0.276\n",
       "Extra credit                   -2.9029      1.860     -1.561      0.119      -6.553       0.747\n",
       "Get ready to read              -3.7070      1.852     -2.002      0.046      -7.342      -0.072\n",
       "Gives good feedback            -2.8392      1.859     -1.528      0.127      -6.487       0.808\n",
       "Graded by few things           -4.2048      1.868     -2.251      0.025      -7.870      -0.539\n",
       "Group projects                 -4.6637      1.867     -2.497      0.013      -8.329      -0.999\n",
       "Hilarious                      -2.8966      1.849     -1.567      0.117      -6.525       0.731\n",
       "Inspirational                  -2.7624      1.857     -1.487      0.137      -6.407       0.883\n",
       "Lecture heavy                  -4.0163      1.853     -2.168      0.030      -7.652      -0.380\n",
       "Lots of homework               -4.0522      1.862     -2.177      0.030      -7.705      -0.399\n",
       "Participation matters          -2.8363      1.864     -1.522      0.128      -6.494       0.821\n",
       "Respected                      -2.2358      1.840     -1.215      0.225      -5.848       1.376\n",
       "Skip class? you won't pass.    -3.5508      1.860     -1.909      0.057      -7.202       0.100\n",
       "So many papers                 -5.7155      1.926     -2.967      0.003      -9.496      -1.935\n",
       "Test heavy                     -5.0964      1.884     -2.705      0.007      -8.794      -1.399\n",
       "Tough grader                   -4.5976      1.846     -2.491      0.013      -8.220      -0.975\n",
       "==============================================================================\n",
       "Omnibus:                       61.682   Durbin-Watson:                   1.877\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               73.841\n",
       "Skew:                          -0.615   Prob(JB):                     9.24e-17\n",
       "Kurtosis:                       3.579   Cond. No.                     3.08e+17\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.85e-23. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prior to normalize\n",
    "X_train, X_test, y_train, y_test=tt_split(dfs_clean, 'Rating', 0.8)\n",
    "\n",
    "model1=sm.OLS(y_train, sm.add_constant(X_train))\n",
    "fit1=model1.fit()\n",
    "fit1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.464</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.450</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   33.62</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 20 Jul 2018</td> <th>  Prob (F-statistic):</th> <td>7.27e-109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:56:56</td>     <th>  Log-Likelihood:    </th> <td> -949.69</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   959</td>      <th>  AIC:               </th> <td>   1949.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   934</td>      <th>  BIC:               </th> <td>   2071.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    24</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    3.8173</td> <td>    0.021</td> <td>  179.097</td> <td> 0.000</td> <td>    3.775</td> <td>    3.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1924</td> <td>    0.025</td> <td>   -7.682</td> <td> 0.000</td> <td>   -0.242</td> <td>   -0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0141</td> <td>    0.022</td> <td>   -0.637</td> <td> 0.524</td> <td>   -0.058</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0049</td> <td>    0.007</td> <td>    0.666</td> <td> 0.505</td> <td>   -0.009</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0035</td> <td>    0.005</td> <td>    0.647</td> <td> 0.518</td> <td>   -0.007</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0035</td> <td>    0.005</td> <td>   -0.647</td> <td> 0.518</td> <td>   -0.014</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.0099</td> <td>    0.011</td> <td>   -0.921</td> <td> 0.357</td> <td>   -0.031</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0035</td> <td>    0.005</td> <td>   -0.647</td> <td> 0.518</td> <td>   -0.014</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0131</td> <td>    0.012</td> <td>    1.066</td> <td> 0.287</td> <td>   -0.011</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.1520</td> <td>    0.135</td> <td>   -1.126</td> <td> 0.260</td> <td>   -0.417</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.2003</td> <td>    0.194</td> <td>   -1.034</td> <td> 0.301</td> <td>   -0.580</td> <td>    0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.1508</td> <td>    0.085</td> <td>   -1.772</td> <td> 0.077</td> <td>   -0.318</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.3081</td> <td>    0.214</td> <td>   -1.437</td> <td> 0.151</td> <td>   -0.729</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.3505</td> <td>    0.193</td> <td>   -1.814</td> <td> 0.070</td> <td>   -0.730</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -0.1956</td> <td>    0.125</td> <td>   -1.561</td> <td> 0.119</td> <td>   -0.442</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.4787</td> <td>    0.239</td> <td>   -2.002</td> <td> 0.046</td> <td>   -0.948</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.3465</td> <td>    0.227</td> <td>   -1.528</td> <td> 0.127</td> <td>   -0.792</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   -0.3246</td> <td>    0.144</td> <td>   -2.251</td> <td> 0.025</td> <td>   -0.608</td> <td>   -0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   -0.3420</td> <td>    0.137</td> <td>   -2.497</td> <td> 0.013</td> <td>   -0.611</td> <td>   -0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.3038</td> <td>    0.194</td> <td>   -1.567</td> <td> 0.117</td> <td>   -0.684</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   -0.3119</td> <td>    0.210</td> <td>   -1.487</td> <td> 0.137</td> <td>   -0.723</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>   -0.5061</td> <td>    0.233</td> <td>   -2.168</td> <td> 0.030</td> <td>   -0.964</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.3964</td> <td>    0.182</td> <td>   -2.177</td> <td> 0.030</td> <td>   -0.754</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.2914</td> <td>    0.191</td> <td>   -1.522</td> <td> 0.128</td> <td>   -0.667</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   -0.2505</td> <td>    0.206</td> <td>   -1.215</td> <td> 0.225</td> <td>   -0.655</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>   -0.3725</td> <td>    0.195</td> <td>   -1.909</td> <td> 0.057</td> <td>   -0.756</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>   -0.2100</td> <td>    0.071</td> <td>   -2.967</td> <td> 0.003</td> <td>   -0.349</td> <td>   -0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>   -0.2283</td> <td>    0.084</td> <td>   -2.705</td> <td> 0.007</td> <td>   -0.394</td> <td>   -0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>   -0.6788</td> <td>    0.273</td> <td>   -2.491</td> <td> 0.013</td> <td>   -1.214</td> <td>   -0.144</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>61.682</td> <th>  Durbin-Watson:     </th> <td>   1.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  73.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.615</td> <th>  Prob(JB):          </th> <td>9.24e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.579</td> <th>  Cond. No.          </th> <td>2.28e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 8.18e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.464\n",
       "Model:                            OLS   Adj. R-squared:                  0.450\n",
       "Method:                 Least Squares   F-statistic:                     33.62\n",
       "Date:                Fri, 20 Jul 2018   Prob (F-statistic):          7.27e-109\n",
       "Time:                        01:56:56   Log-Likelihood:                -949.69\n",
       "No. Observations:                 959   AIC:                             1949.\n",
       "Df Residuals:                     934   BIC:                             2071.\n",
       "Df Model:                          24                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          3.8173      0.021    179.097      0.000       3.775       3.859\n",
       "x1            -0.1924      0.025     -7.682      0.000      -0.242      -0.143\n",
       "x2            -0.0141      0.022     -0.637      0.524      -0.058       0.029\n",
       "x3             0.0049      0.007      0.666      0.505      -0.009       0.019\n",
       "x4             0.0035      0.005      0.647      0.518      -0.007       0.014\n",
       "x5            -0.0035      0.005     -0.647      0.518      -0.014       0.007\n",
       "x6            -0.0099      0.011     -0.921      0.357      -0.031       0.011\n",
       "x7            -0.0035      0.005     -0.647      0.518      -0.014       0.007\n",
       "x8             0.0131      0.012      1.066      0.287      -0.011       0.037\n",
       "x9            -0.1520      0.135     -1.126      0.260      -0.417       0.113\n",
       "x10           -0.2003      0.194     -1.034      0.301      -0.580       0.180\n",
       "x11           -0.1508      0.085     -1.772      0.077      -0.318       0.016\n",
       "x12           -0.3081      0.214     -1.437      0.151      -0.729       0.113\n",
       "x13           -0.3505      0.193     -1.814      0.070      -0.730       0.029\n",
       "x14           -0.1956      0.125     -1.561      0.119      -0.442       0.050\n",
       "x15           -0.4787      0.239     -2.002      0.046      -0.948      -0.009\n",
       "x16           -0.3465      0.227     -1.528      0.127      -0.792       0.099\n",
       "x17           -0.3246      0.144     -2.251      0.025      -0.608      -0.042\n",
       "x18           -0.3420      0.137     -2.497      0.013      -0.611      -0.073\n",
       "x19           -0.3038      0.194     -1.567      0.117      -0.684       0.077\n",
       "x20           -0.3119      0.210     -1.487      0.137      -0.723       0.100\n",
       "x21           -0.5061      0.233     -2.168      0.030      -0.964      -0.048\n",
       "x22           -0.3964      0.182     -2.177      0.030      -0.754      -0.039\n",
       "x23           -0.2914      0.191     -1.522      0.128      -0.667       0.084\n",
       "x24           -0.2505      0.206     -1.215      0.225      -0.655       0.154\n",
       "x25           -0.3725      0.195     -1.909      0.057      -0.756       0.010\n",
       "x26           -0.2100      0.071     -2.967      0.003      -0.349      -0.071\n",
       "x27           -0.2283      0.084     -2.705      0.007      -0.394      -0.063\n",
       "x28           -0.6788      0.273     -2.491      0.013      -1.214      -0.144\n",
       "==============================================================================\n",
       "Omnibus:                       61.682   Durbin-Watson:                   1.877\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               73.841\n",
       "Skew:                          -0.615   Prob(JB):                     9.24e-17\n",
       "Kurtosis:                       3.579   Cond. No.                     2.28e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.18e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model: noted y is not normal distribution. Leave it untransformed in this scenario\n",
    "\n",
    "# Perform training and testing splits\n",
    "\n",
    "X_train, X_test, y_train, y_test=tt_split(dfs_clean, 'Rating', 0.8)\n",
    "\n",
    "# normalize training set\n",
    "\n",
    "ssX = StandardScaler()\n",
    "X_train_scaled = ssX.fit_transform(X_train)\n",
    "\n",
    "\n",
    "model1=sm.OLS(y_train, sm.add_constant(X_train_scaled))\n",
    "fit1=model1.fit()\n",
    "fit1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 32}\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fit1.resid.plot(style='o', figsize=(12,8))\n",
    "plt.ylabel('Rating')\n",
    "plt.title('Risidual Plot')\n",
    "plt.rc('font', **font)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diagnostic_plots.diagnostic_plots(dfs_clean.drop('Rating', axis=1), dfs_clean['Rating'], fit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   30.12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 20 Jul 2018</td> <th>  Prob (F-statistic):</th> <td>4.21e-99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:56:57</td>     <th>  Log-Likelihood:    </th> <td>  371.77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   959</td>      <th>  AIC:               </th> <td>  -693.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   934</td>      <th>  BIC:               </th> <td>  -571.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    24</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                       <td>    0.0715</td> <td>    0.015</td> <td>    4.665</td> <td> 0.000</td> <td>    0.041</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Level of difficulty</th>         <td>   -0.0592</td> <td>    0.008</td> <td>   -7.086</td> <td> 0.000</td> <td>   -0.076</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total reviews</th>               <td>    0.0082</td> <td>    0.006</td> <td>    1.344</td> <td> 0.179</td> <td>   -0.004</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Student size</th>                <td> 3.963e-05</td> <td> 8.32e-06</td> <td>    4.763</td> <td> 0.000</td> <td> 2.33e-05</td> <td>  5.6e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_public</th>                 <td>    0.1756</td> <td>    0.037</td> <td>    4.720</td> <td> 0.000</td> <td>    0.103</td> <td>    0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_private</th>                <td>   -0.1041</td> <td>    0.022</td> <td>   -4.737</td> <td> 0.000</td> <td>   -0.147</td> <td>   -0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_west</th>                 <td>    0.2914</td> <td>    0.063</td> <td>    4.635</td> <td> 0.000</td> <td>    0.168</td> <td>    0.415</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_east</th>                 <td>   -0.1041</td> <td>    0.022</td> <td>   -4.737</td> <td> 0.000</td> <td>   -0.147</td> <td>   -0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_south</th>                <td>   -0.1158</td> <td>    0.026</td> <td>   -4.401</td> <td> 0.000</td> <td>   -0.167</td> <td>   -0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Accessible outside class</th>    <td>   -0.6907</td> <td>    0.470</td> <td>   -1.469</td> <td> 0.142</td> <td>   -1.613</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Amazing lectures</th>            <td>   -0.6326</td> <td>    0.467</td> <td>   -1.355</td> <td> 0.176</td> <td>   -1.549</td> <td>    0.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Beware of pop quizzes</th>       <td>   -0.8790</td> <td>    0.483</td> <td>   -1.819</td> <td> 0.069</td> <td>   -1.827</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Caring</th>                      <td>   -0.8033</td> <td>    0.468</td> <td>   -1.716</td> <td> 0.086</td> <td>   -1.722</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clear grading criteria</th>      <td>   -0.9279</td> <td>    0.468</td> <td>   -1.983</td> <td> 0.048</td> <td>   -1.846</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Extra credit</th>                <td>   -0.8275</td> <td>    0.469</td> <td>   -1.765</td> <td> 0.078</td> <td>   -1.748</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Get ready to read</th>           <td>   -1.0310</td> <td>    0.467</td> <td>   -2.208</td> <td> 0.027</td> <td>   -1.947</td> <td>   -0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gives good feedback</th>         <td>   -0.8260</td> <td>    0.469</td> <td>   -1.763</td> <td> 0.078</td> <td>   -1.745</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Graded by few things</th>        <td>   -1.1026</td> <td>    0.471</td> <td>   -2.342</td> <td> 0.019</td> <td>   -2.027</td> <td>   -0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Group projects</th>              <td>   -1.2307</td> <td>    0.471</td> <td>   -2.614</td> <td> 0.009</td> <td>   -2.155</td> <td>   -0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hilarious</th>                   <td>   -0.8491</td> <td>    0.466</td> <td>   -1.822</td> <td> 0.069</td> <td>   -1.764</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Inspirational</th>               <td>   -0.8072</td> <td>    0.468</td> <td>   -1.724</td> <td> 0.085</td> <td>   -1.726</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lecture heavy</th>               <td>   -1.1080</td> <td>    0.467</td> <td>   -2.372</td> <td> 0.018</td> <td>   -2.025</td> <td>   -0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lots of homework</th>            <td>   -1.1077</td> <td>    0.469</td> <td>   -2.360</td> <td> 0.018</td> <td>   -2.029</td> <td>   -0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Participation matters</th>       <td>   -0.8099</td> <td>    0.470</td> <td>   -1.724</td> <td> 0.085</td> <td>   -1.732</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Respected</th>                   <td>   -0.7001</td> <td>    0.464</td> <td>   -1.509</td> <td> 0.132</td> <td>   -1.611</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skip class? you won't pass.</th> <td>   -0.9535</td> <td>    0.469</td> <td>   -2.033</td> <td> 0.042</td> <td>   -1.874</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>So many papers</th>              <td>   -1.5344</td> <td>    0.486</td> <td>   -3.160</td> <td> 0.002</td> <td>   -2.487</td> <td>   -0.581</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Test heavy</th>                  <td>   -1.3536</td> <td>    0.475</td> <td>   -2.850</td> <td> 0.004</td> <td>   -2.286</td> <td>   -0.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tough grader</th>                <td>   -1.3080</td> <td>    0.465</td> <td>   -2.811</td> <td> 0.005</td> <td>   -2.221</td> <td>   -0.395</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>246.605</td> <th>  Durbin-Watson:     </th> <td>   1.921</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 689.613</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.297</td>  <th>  Prob(JB):          </th> <td>1.79e-150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.246</td>  <th>  Cond. No.          </th> <td>3.08e+17</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.85e-23. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.436\n",
       "Model:                            OLS   Adj. R-squared:                  0.422\n",
       "Method:                 Least Squares   F-statistic:                     30.12\n",
       "Date:                Fri, 20 Jul 2018   Prob (F-statistic):           4.21e-99\n",
       "Time:                        01:56:57   Log-Likelihood:                 371.77\n",
       "No. Observations:                 959   AIC:                            -693.5\n",
       "Df Residuals:                     934   BIC:                            -571.9\n",
       "Df Model:                          24                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "const                           0.0715      0.015      4.665      0.000       0.041       0.102\n",
       "Level of difficulty            -0.0592      0.008     -7.086      0.000      -0.076      -0.043\n",
       "Total reviews                   0.0082      0.006      1.344      0.179      -0.004       0.020\n",
       "Student size                 3.963e-05   8.32e-06      4.763      0.000    2.33e-05     5.6e-05\n",
       "Type_public                     0.1756      0.037      4.720      0.000       0.103       0.249\n",
       "Type_private                   -0.1041      0.022     -4.737      0.000      -0.147      -0.061\n",
       "Region_west                     0.2914      0.063      4.635      0.000       0.168       0.415\n",
       "Region_east                    -0.1041      0.022     -4.737      0.000      -0.147      -0.061\n",
       "Region_south                   -0.1158      0.026     -4.401      0.000      -0.167      -0.064\n",
       "Accessible outside class       -0.6907      0.470     -1.469      0.142      -1.613       0.232\n",
       "Amazing lectures               -0.6326      0.467     -1.355      0.176      -1.549       0.284\n",
       "Beware of pop quizzes          -0.8790      0.483     -1.819      0.069      -1.827       0.069\n",
       "Caring                         -0.8033      0.468     -1.716      0.086      -1.722       0.115\n",
       "Clear grading criteria         -0.9279      0.468     -1.983      0.048      -1.846      -0.010\n",
       "Extra credit                   -0.8275      0.469     -1.765      0.078      -1.748       0.093\n",
       "Get ready to read              -1.0310      0.467     -2.208      0.027      -1.947      -0.115\n",
       "Gives good feedback            -0.8260      0.469     -1.763      0.078      -1.745       0.094\n",
       "Graded by few things           -1.1026      0.471     -2.342      0.019      -2.027      -0.179\n",
       "Group projects                 -1.2307      0.471     -2.614      0.009      -2.155      -0.307\n",
       "Hilarious                      -0.8491      0.466     -1.822      0.069      -1.764       0.065\n",
       "Inspirational                  -0.8072      0.468     -1.724      0.085      -1.726       0.112\n",
       "Lecture heavy                  -1.1080      0.467     -2.372      0.018      -2.025      -0.191\n",
       "Lots of homework               -1.1077      0.469     -2.360      0.018      -2.029      -0.187\n",
       "Participation matters          -0.8099      0.470     -1.724      0.085      -1.732       0.112\n",
       "Respected                      -0.7001      0.464     -1.509      0.132      -1.611       0.210\n",
       "Skip class? you won't pass.    -0.9535      0.469     -2.033      0.042      -1.874      -0.033\n",
       "So many papers                 -1.5344      0.486     -3.160      0.002      -2.487      -0.581\n",
       "Test heavy                     -1.3536      0.475     -2.850      0.004      -2.286      -0.422\n",
       "Tough grader                   -1.3080      0.465     -2.811      0.005      -2.221      -0.395\n",
       "==============================================================================\n",
       "Omnibus:                      246.605   Durbin-Watson:                   1.921\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              689.613\n",
       "Skew:                          -1.297   Prob(JB):                    1.79e-150\n",
       "Kurtosis:                       6.246   Cond. No.                     3.08e+17\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.85e-23. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tested Box transformation and noted worse result\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "dfs_box=dfs_clean.copy()\n",
    "lamb=stats.boxcox_normmax(dfs_box.Rating, brack=(-1.9, 1.9))\n",
    "\n",
    "dfs_box.Rating=(np.power(dfs_box.Rating,-0.2282)-1)/-0.2282\n",
    "\n",
    "plt.hist(dfs_box.Rating);\n",
    "\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2=tt_split(dfs_box, 'Rating', 0.8)\n",
    "ssX2 = StandardScaler()\n",
    "X_train_scaled2 = ssX.fit_transform(X_train2)\n",
    "\n",
    "\n",
    "\n",
    "model2=sm.OLS(y_train2, sm.add_constant(X_train2))\n",
    "fit2=model2.fit()\n",
    "fit2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Rating</td>      <th>  R-squared:         </th> <td>   0.445</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.430</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   31.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 20 Jul 2018</td> <th>  Prob (F-statistic):</th> <td>4.51e-102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:56:57</td>     <th>  Log-Likelihood:    </th> <td>  144.07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   959</td>      <th>  AIC:               </th> <td>  -238.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   934</td>      <th>  BIC:               </th> <td>  -116.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    24</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                       <td>    0.0863</td> <td>    0.019</td> <td>    4.439</td> <td> 0.000</td> <td>    0.048</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Level of difficulty</th>         <td>   -0.0769</td> <td>    0.011</td> <td>   -7.259</td> <td> 0.000</td> <td>   -0.098</td> <td>   -0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Total reviews</th>               <td>    0.0075</td> <td>    0.008</td> <td>    0.963</td> <td> 0.336</td> <td>   -0.008</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Student size</th>                <td>  4.79e-05</td> <td> 1.06e-05</td> <td>    4.539</td> <td> 0.000</td> <td> 2.72e-05</td> <td> 6.86e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_public</th>                 <td>    0.2125</td> <td>    0.047</td> <td>    4.504</td> <td> 0.000</td> <td>    0.120</td> <td>    0.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_private</th>                <td>   -0.1262</td> <td>    0.028</td> <td>   -4.529</td> <td> 0.000</td> <td>   -0.181</td> <td>   -0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_west</th>                 <td>    0.3513</td> <td>    0.080</td> <td>    4.406</td> <td> 0.000</td> <td>    0.195</td> <td>    0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_east</th>                 <td>   -0.1262</td> <td>    0.028</td> <td>   -4.529</td> <td> 0.000</td> <td>   -0.181</td> <td>   -0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Region_south</th>                <td>   -0.1388</td> <td>    0.033</td> <td>   -4.159</td> <td> 0.000</td> <td>   -0.204</td> <td>   -0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Accessible outside class</th>    <td>   -0.8327</td> <td>    0.596</td> <td>   -1.397</td> <td> 0.163</td> <td>   -2.003</td> <td>    0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Amazing lectures</th>            <td>   -0.7628</td> <td>    0.592</td> <td>   -1.289</td> <td> 0.198</td> <td>   -1.924</td> <td>    0.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Beware of pop quizzes</th>       <td>   -1.1096</td> <td>    0.613</td> <td>   -1.811</td> <td> 0.070</td> <td>   -2.312</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Caring</th>                      <td>   -0.9853</td> <td>    0.593</td> <td>   -1.660</td> <td> 0.097</td> <td>   -2.150</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Clear grading criteria</th>      <td>   -1.1576</td> <td>    0.593</td> <td>   -1.951</td> <td> 0.051</td> <td>   -2.322</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Extra credit</th>                <td>   -1.0256</td> <td>    0.594</td> <td>   -1.725</td> <td> 0.085</td> <td>   -2.192</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Get ready to read</th>           <td>   -1.2853</td> <td>    0.592</td> <td>   -2.171</td> <td> 0.030</td> <td>   -2.447</td> <td>   -0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gives good feedback</th>         <td>   -1.0201</td> <td>    0.594</td> <td>   -1.717</td> <td> 0.086</td> <td>   -2.186</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Graded by few things</th>        <td>   -1.3895</td> <td>    0.597</td> <td>   -2.327</td> <td> 0.020</td> <td>   -2.561</td> <td>   -0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Group projects</th>              <td>   -1.5524</td> <td>    0.597</td> <td>   -2.601</td> <td> 0.009</td> <td>   -2.724</td> <td>   -0.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hilarious</th>                   <td>   -1.0471</td> <td>    0.591</td> <td>   -1.772</td> <td> 0.077</td> <td>   -2.207</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Inspirational</th>               <td>   -0.9954</td> <td>    0.594</td> <td>   -1.677</td> <td> 0.094</td> <td>   -2.160</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lecture heavy</th>               <td>   -1.3839</td> <td>    0.592</td> <td>   -2.337</td> <td> 0.020</td> <td>   -2.546</td> <td>   -0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Lots of homework</th>            <td>   -1.3856</td> <td>    0.595</td> <td>   -2.329</td> <td> 0.020</td> <td>   -2.553</td> <td>   -0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Participation matters</th>       <td>   -1.0022</td> <td>    0.596</td> <td>   -1.682</td> <td> 0.093</td> <td>   -2.171</td> <td>    0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Respected</th>                   <td>   -0.8521</td> <td>    0.588</td> <td>   -1.448</td> <td> 0.148</td> <td>   -2.007</td> <td>    0.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skip class? you won't pass.</th> <td>   -1.1965</td> <td>    0.595</td> <td>   -2.012</td> <td> 0.044</td> <td>   -2.363</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>So many papers</th>              <td>   -1.9306</td> <td>    0.616</td> <td>   -3.135</td> <td> 0.002</td> <td>   -3.139</td> <td>   -0.722</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Test heavy</th>                  <td>   -1.7045</td> <td>    0.602</td> <td>   -2.830</td> <td> 0.005</td> <td>   -2.886</td> <td>   -0.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tough grader</th>                <td>   -1.6241</td> <td>    0.590</td> <td>   -2.753</td> <td> 0.006</td> <td>   -2.782</td> <td>   -0.466</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>189.756</td> <th>  Durbin-Watson:     </th> <td>   1.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 403.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.106</td>  <th>  Prob(JB):          </th> <td>1.94e-88</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.283</td>  <th>  Cond. No.          </th> <td>3.08e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.85e-23. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Rating   R-squared:                       0.445\n",
       "Model:                            OLS   Adj. R-squared:                  0.430\n",
       "Method:                 Least Squares   F-statistic:                     31.17\n",
       "Date:                Fri, 20 Jul 2018   Prob (F-statistic):          4.51e-102\n",
       "Time:                        01:56:57   Log-Likelihood:                 144.07\n",
       "No. Observations:                 959   AIC:                            -238.1\n",
       "Df Residuals:                     934   BIC:                            -116.5\n",
       "Df Model:                          24                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "const                           0.0863      0.019      4.439      0.000       0.048       0.124\n",
       "Level of difficulty            -0.0769      0.011     -7.259      0.000      -0.098      -0.056\n",
       "Total reviews                   0.0075      0.008      0.963      0.336      -0.008       0.023\n",
       "Student size                  4.79e-05   1.06e-05      4.539      0.000    2.72e-05    6.86e-05\n",
       "Type_public                     0.2125      0.047      4.504      0.000       0.120       0.305\n",
       "Type_private                   -0.1262      0.028     -4.529      0.000      -0.181      -0.072\n",
       "Region_west                     0.3513      0.080      4.406      0.000       0.195       0.508\n",
       "Region_east                    -0.1262      0.028     -4.529      0.000      -0.181      -0.072\n",
       "Region_south                   -0.1388      0.033     -4.159      0.000      -0.204      -0.073\n",
       "Accessible outside class       -0.8327      0.596     -1.397      0.163      -2.003       0.337\n",
       "Amazing lectures               -0.7628      0.592     -1.289      0.198      -1.924       0.399\n",
       "Beware of pop quizzes          -1.1096      0.613     -1.811      0.070      -2.312       0.093\n",
       "Caring                         -0.9853      0.593     -1.660      0.097      -2.150       0.179\n",
       "Clear grading criteria         -1.1576      0.593     -1.951      0.051      -2.322       0.007\n",
       "Extra credit                   -1.0256      0.594     -1.725      0.085      -2.192       0.141\n",
       "Get ready to read              -1.2853      0.592     -2.171      0.030      -2.447      -0.123\n",
       "Gives good feedback            -1.0201      0.594     -1.717      0.086      -2.186       0.146\n",
       "Graded by few things           -1.3895      0.597     -2.327      0.020      -2.561      -0.218\n",
       "Group projects                 -1.5524      0.597     -2.601      0.009      -2.724      -0.381\n",
       "Hilarious                      -1.0471      0.591     -1.772      0.077      -2.207       0.113\n",
       "Inspirational                  -0.9954      0.594     -1.677      0.094      -2.160       0.170\n",
       "Lecture heavy                  -1.3839      0.592     -2.337      0.020      -2.546      -0.222\n",
       "Lots of homework               -1.3856      0.595     -2.329      0.020      -2.553      -0.218\n",
       "Participation matters          -1.0022      0.596     -1.682      0.093      -2.171       0.167\n",
       "Respected                      -0.8521      0.588     -1.448      0.148      -2.007       0.302\n",
       "Skip class? you won't pass.    -1.1965      0.595     -2.012      0.044      -2.363      -0.029\n",
       "So many papers                 -1.9306      0.616     -3.135      0.002      -3.139      -0.722\n",
       "Test heavy                     -1.7045      0.602     -2.830      0.005      -2.886      -0.523\n",
       "Tough grader                   -1.6241      0.590     -2.753      0.006      -2.782      -0.466\n",
       "==============================================================================\n",
       "Omnibus:                      189.756   Durbin-Watson:                   1.910\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              403.931\n",
       "Skew:                          -1.106   Prob(JB):                     1.94e-88\n",
       "Kurtosis:                       5.283   Cond. No.                     3.08e+17\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.85e-23. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tested log transform of y, and noted worse result\n",
    "\n",
    "dfs_log=dfs_clean.copy()\n",
    "dfs_log['Rating']=np.log(dfs_log['Rating'])\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3=tt_split(dfs_log, 'Rating', 0.8)\n",
    "ssX3 = StandardScaler()\n",
    "X_train_scaled3 = ssX.fit_transform(X_train3)\n",
    "\n",
    "\n",
    "model3=sm.OLS(y_train3, sm.add_constant(X_train3))\n",
    "fit3=model3.fit()\n",
    "fit3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rating', 'Level of difficulty', 'Total reviews', 'Student size',\n",
       "       'Type_public', 'Type_private', 'Region_west', 'Region_east',\n",
       "       'Region_south', 'Accessible outside class', 'Amazing lectures',\n",
       "       'Beware of pop quizzes', 'Caring', 'Clear grading criteria',\n",
       "       'Extra credit', 'Get ready to read', 'Gives good feedback',\n",
       "       'Graded by few things', 'Group projects', 'Hilarious', 'Inspirational',\n",
       "       'Lecture heavy', 'Lots of homework', 'Participation matters',\n",
       "       'Respected', 'Skip class? you won't pass.', 'So many papers',\n",
       "       'Test heavy', 'Tough grader'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ran iterations of models and only keep key features that can impact rating\n",
    "\n",
    "dfs_clean_smaller=dfs_clean.loc[:,['Rating', 'Level of difficulty',  \n",
    "        'Accessible outside class', 'Amazing lectures','Caring', 'Clear grading criteria',\n",
    "        'Gives good feedback',\n",
    "        'Hilarious', 'Inspirational',\n",
    "         'Participation matters',\n",
    "       'Respected', 'Skip class? you won\\'t pass.' \n",
    "        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 4 with lasso approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=tt_split(dfs_clean_smaller, 'Rating', 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSX4=StandardScaler()\n",
    "X_train_scaled=SSX4.fit_transform(X_train)\n",
    "X_test_scaled=SSX4.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "\n",
    "est=make_pipeline(PolynomialFeatures(2), Lasso(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'polynomialfeatures', 'lasso', 'polynomialfeatures__degree', 'polynomialfeatures__include_bias', 'polynomialfeatures__interaction_only', 'lasso__alpha', 'lasso__copy_X', 'lasso__fit_intercept', 'lasso__max_iter', 'lasso__normalize', 'lasso__positive', 'lasso__precompute', 'lasso__random_state', 'lasso__selection', 'lasso__tol', 'lasso__warm_start'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#est.get_params().keys()\n",
    "#est.set_params(polynomialfeatures__degree=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('polynomialfeatures', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('lasso', Lasso(alpha=1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'lasso__alpha': [0.0001, 0.001, 0.01, 0.1, 1], 'polynomialfeatures__degree': [1, 2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'lasso__alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1] , 'polynomialfeatures__degree': [1, 2, 3]}\n",
    "grid = GridSearchCV(est, param_grid=params, cv=5)\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.22535961,  0.14365742,  0.22973502,  0.16639805,\n",
       "        0.0845174 ,  0.15943565,  0.1285289 ,  0.15785578,  0.13537392,\n",
       "        0.20265492,  0.06205456])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.get_params()['lasso'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasso__alpha': 0.001, 'polynomialfeatures__degree': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4057764442229708"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Level of difficulty</th>\n",
       "      <th>Accessible outside class</th>\n",
       "      <th>Amazing lectures</th>\n",
       "      <th>Caring</th>\n",
       "      <th>Clear grading criteria</th>\n",
       "      <th>Gives good feedback</th>\n",
       "      <th>Hilarious</th>\n",
       "      <th>Inspirational</th>\n",
       "      <th>Participation matters</th>\n",
       "      <th>Respected</th>\n",
       "      <th>Skip class? you won't pass.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>berkely</th>\n",
       "      <th>692</th>\n",
       "      <td>3.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyu</th>\n",
       "      <th>489</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">uf</th>\n",
       "      <th>1420</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4245</th>\n",
       "      <td>3.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berkely</th>\n",
       "      <th>206</th>\n",
       "      <td>1.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Level of difficulty  Accessible outside class  Amazing lectures  \\\n",
       "berkely 692                   3.9                      0.00               0.0   \n",
       "nyu     489                   3.5                      0.00               0.0   \n",
       "uf      1420                  3.0                      0.08               0.0   \n",
       "        4245                  3.3                      0.00               0.0   \n",
       "berkely 206                   1.9                      0.00               0.0   \n",
       "\n",
       "              Caring  Clear grading criteria  Gives good feedback  Hilarious  \\\n",
       "berkely 692     0.00                    0.00                 0.00       0.00   \n",
       "nyu     489     0.00                    0.25                 0.00       0.00   \n",
       "uf      1420    0.08                    0.00                 0.00       0.08   \n",
       "        4245    0.08                    0.00                 0.17       0.00   \n",
       "berkely 206     0.20                    0.00                 0.00       0.00   \n",
       "\n",
       "              Inspirational  Participation matters  Respected  \\\n",
       "berkely 692            0.00                    0.0       0.00   \n",
       "nyu     489            0.00                    0.0       0.00   \n",
       "uf      1420           0.25                    0.0       0.17   \n",
       "        4245           0.08                    0.0       0.00   \n",
       "berkely 206            0.40                    0.0       0.40   \n",
       "\n",
       "              Skip class? you won't pass.  \n",
       "berkely 692                          0.00  \n",
       "nyu     489                          0.00  \n",
       "uf      1420                         0.00  \n",
       "        4245                         0.25  \n",
       "berkely 206                          0.00  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modle 5 with Ridge model\n",
    "\n",
    "degree=2\n",
    "alphas= 1  #[1e-5, 1e-4, 1e-3,1e-2,1e-1]\n",
    "\n",
    "\n",
    "est2=make_pipeline(PolynomialFeatures(degree), Ridge(alpha=alphas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'polynomialfeatures', 'ridge', 'polynomialfeatures__degree', 'polynomialfeatures__include_bias', 'polynomialfeatures__interaction_only', 'ridge__alpha', 'ridge__copy_X', 'ridge__fit_intercept', 'ridge__max_iter', 'ridge__normalize', 'ridge__random_state', 'ridge__solver', 'ridge__tol'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est2.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('polynomialfeatures', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('ridge', Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'ridge__alpha': [0.0001, 0.001, 0.01, 0.1, 1], 'polynomialfeatures__degree': [1, 2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params2 = {'ridge__alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1] , 'polynomialfeatures__degree': [1, 2, 3]}\n",
    "grid2 = GridSearchCV(est2, param_grid=params2, cv=5)\n",
    "grid2.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.22503536,  0.14483339,  0.23082068,  0.16745131,\n",
       "        0.08628523,  0.16073567,  0.1298527 ,  0.15906314,  0.13681713,\n",
       "        0.20366588,  0.06403286])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2.best_estimator_.get_params()['ridge'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'polynomialfeatures__degree': 1, 'ridge__alpha': 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4055806422490368"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 6: Elastic Net\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree=2\n",
    "alphas=1\n",
    "\n",
    "est3=make_pipeline(PolynomialFeatures(degree), ElasticNet(alpha=alphas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'polynomialfeatures', 'elasticnet', 'polynomialfeatures__degree', 'polynomialfeatures__include_bias', 'polynomialfeatures__interaction_only', 'elasticnet__alpha', 'elasticnet__copy_X', 'elasticnet__fit_intercept', 'elasticnet__l1_ratio', 'elasticnet__max_iter', 'elasticnet__normalize', 'elasticnet__positive', 'elasticnet__precompute', 'elasticnet__random_state', 'elasticnet__selection', 'elasticnet__tol', 'elasticnet__warm_start'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est3.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('polynomialfeatures', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'elasticnet__alpha': [0.0001, 0.001, 0.01, 0.1, 1], 'polynomialfeatures__degree': [1, 2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'elasticnet__alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1] , 'polynomialfeatures__degree': [1, 2, 3]}\n",
    "grid3 = GridSearchCV(est3, param_grid=params, cv=5)\n",
    "grid3.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elasticnet__alpha': 0.01, 'polynomialfeatures__degree': 1}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.22606538,  0.13724594,  0.22296543,  0.16071689,\n",
       "        0.07571041,  0.15233942,  0.12175314,  0.15159818,  0.12760483,\n",
       "        0.19684617,  0.05197278])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid3.best_estimator_.get_params()['elasticnet'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.406398317554983"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid3.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Level of difficulty</th>\n",
       "      <th>Accessible outside class</th>\n",
       "      <th>Amazing lectures</th>\n",
       "      <th>Caring</th>\n",
       "      <th>Clear grading criteria</th>\n",
       "      <th>Gives good feedback</th>\n",
       "      <th>Hilarious</th>\n",
       "      <th>Inspirational</th>\n",
       "      <th>Participation matters</th>\n",
       "      <th>Respected</th>\n",
       "      <th>Skip class? you won't pass.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>berkely</th>\n",
       "      <th>692</th>\n",
       "      <td>3.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyu</th>\n",
       "      <th>489</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">uf</th>\n",
       "      <th>1420</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4245</th>\n",
       "      <td>3.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berkely</th>\n",
       "      <th>206</th>\n",
       "      <td>1.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Level of difficulty  Accessible outside class  Amazing lectures  \\\n",
       "berkely 692                   3.9                      0.00               0.0   \n",
       "nyu     489                   3.5                      0.00               0.0   \n",
       "uf      1420                  3.0                      0.08               0.0   \n",
       "        4245                  3.3                      0.00               0.0   \n",
       "berkely 206                   1.9                      0.00               0.0   \n",
       "\n",
       "              Caring  Clear grading criteria  Gives good feedback  Hilarious  \\\n",
       "berkely 692     0.00                    0.00                 0.00       0.00   \n",
       "nyu     489     0.00                    0.25                 0.00       0.00   \n",
       "uf      1420    0.08                    0.00                 0.00       0.08   \n",
       "        4245    0.08                    0.00                 0.17       0.00   \n",
       "berkely 206     0.20                    0.00                 0.00       0.00   \n",
       "\n",
       "              Inspirational  Participation matters  Respected  \\\n",
       "berkely 692            0.00                    0.0       0.00   \n",
       "nyu     489            0.00                    0.0       0.00   \n",
       "uf      1420           0.25                    0.0       0.17   \n",
       "        4245           0.08                    0.0       0.00   \n",
       "berkely 206            0.40                    0.0       0.40   \n",
       "\n",
       "              Skip class? you won't pass.  \n",
       "berkely 692                          0.00  \n",
       "nyu     489                          0.00  \n",
       "uf      1420                         0.00  \n",
       "        4245                         0.25  \n",
       "berkely 206                          0.00  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final=X_train.drop(['Clear grading criteria', \"Skip class? you won't pass.\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Level of difficulty', 'Accessible outside class', 'Amazing lectures',\n",
       "       'Caring', 'Gives good feedback', 'Hilarious', 'Inspirational',\n",
       "       'Participation matters', 'Respected'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 9)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-4191b684f7af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fit4' is not defined"
     ]
    }
   ],
   "source": [
    "fit4.resid.plot(style='o', figsize=(12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_plots.diagnostic_plots(dfs_clean.drop(['Name','Rating'], axis=1), dfs_clean['Rating'], fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_log.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
