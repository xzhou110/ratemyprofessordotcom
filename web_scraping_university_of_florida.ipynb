{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Being a data scientist, the real sh*t:\n",
    "\n",
    "* Data scientists in real life have multiple goals that fit under the\n",
    "  general category of \"making sense of data\" or \"turning data into\n",
    "  insights\".\n",
    "  * Often we are focused on building a predictive model, and on\n",
    "    maximizing the predictive model's accuracy. Sometimes this focus\n",
    "    is overemphasized. This is a thing that we do, but this is not the\n",
    "    only thing.\n",
    "    * Things that fail are often still interesting insights.\n",
    "    * Anecdotes are often interesting insights.\n",
    "    * The utility of an analysis is independent of the sophistication\n",
    "      of the algorithm. Sometimes the most mind-blowing insights come\n",
    "      from lists, tables, histograms, or scatter plots. Don't throw\n",
    "      out cool stuff that isn't technically advanced unless absolutely\n",
    "      necessary.\n",
    "      * Don't over-design and under-deliver. For every data science\n",
    "        project that you see or hear about, the version in the data\n",
    "        scientist's head was probably fancier, bigger, more\n",
    "        comprehensive, more elegant, presented in a cooler format, or\n",
    "        with better copy, et cetera, ad nauseum. The reason you heard\n",
    "        about it at all, however, is because it was *finished*, and\n",
    "        published or released in all its heart-wrenching\n",
    "        imperfection.\n",
    "        * Start with something small, and build from there, as\n",
    "        necessary, as time allows.\n",
    "        * Jot down the elaborations, next steps, uh-ohs, or grand\n",
    "          ideas that strike you as you are working. Leave them alone\n",
    "          for a while and then come back and look at them later.\n",
    "          * Many things that feel like huge \"uhoh\"s in the heat of the\n",
    "            moment are actually small deals or even false alarms. The\n",
    "            fewer of these you spend time on, the better.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xzhou/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.core.display import display, HTML\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "#import diagnostic_plots\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# school starting page:  http://www.ratemyprofessors.com/search.jsp?query=&queryoption=HEADER&stateselect=&country=&dept=&queryBy=teacherName&facetSearch=&schoolName=University+of+California+Berkeley&offset=0&max=20\n",
    "# example professor: http://www.ratemyprofessors.com/ShowRatings.jsp?tid=7503\n",
    "\n",
    "# each school contains multiple pages of listing. school_url_flex is used to generate link of different pages\n",
    "# links with _flex suffix means the link is flexible and can take in different parameters for website navigation\n",
    "\n",
    "school_url=\"http://www.ratemyprofessors.com/search.jsp?query=&queryoption=HEADER&stateselect=&country=&dept=&queryBy=teacherName&facetSearch=&schoolName=University+of+Florida&offset=0&max=20\"\n",
    "school_url_flex=\"http://www.ratemyprofessors.com/search.jsp?query=&queryoption=HEADER&stateselect=&country=&dept=&queryBy=teacherName&facetSearch=&schoolName=University+of+Florida&offset={}&max=20\"\n",
    "prof_url=\"http://www.ratemyprofessors.com/ShowRatings.jsp?tid=144\"\n",
    "prof_url_flex=\"http://www.ratemyprofessors.com{}\"\n",
    "\n",
    "prof_response=requests.get(prof_url)\n",
    "school_response=requests.get(school_url)\n",
    "\n",
    "print(prof_response.status_code)\n",
    "print(school_response.status_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_page=prof_response.text\n",
    "school_page=school_response.text\n",
    "\n",
    "prof_soup = BeautifulSoup(prof_page,\"lxml\")\n",
    "school_soup = BeautifulSoup(school_page,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5307"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of professor listings in a school. Given school soup, retun number of professors\n",
    "\n",
    "def total_professors(school_soup):\n",
    "    for e in school_soup.find_all(class_=\"toppager\"):     #(class_=\"toppager-left\"):\n",
    "        temp=e.find(class_=\"result-count\").text\n",
    "       # name=e.find(class_=\"pfname\").text.strip()+\" \"+e.find(class_=\"plname\").text.strip()\n",
    "        result=re.findall(r'\\d+', temp)\n",
    "        return int(max(result)) #usually the pages shows 1-20 records out of x result. x would be the maximum of the three number\n",
    "\n",
    "total_prof=total_professors(school_soup)\n",
    "total_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def page_of_listing(total_professors):\n",
    "    pages=total_professors//20+1\n",
    "    return pages\n",
    "\n",
    "test=page_of_listing(total_prof)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.ratemyprofessors.com/search.jsp?query=&queryoption=HEADER&stateselect=&country=&dept=&queryBy=teacherName&facetSearch=&schoolName=University+of+Florida&offset=0&max=20',\n",
       " 'http://www.ratemyprofessors.com/search.jsp?query=&queryoption=HEADER&stateselect=&country=&dept=&queryBy=teacherName&facetSearch=&schoolName=University+of+Florida&offset=20&max=20']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given school's flexible url and pages of listing, generae a list of urls of all webpage pages\n",
    "def page_urls(url_flex, pages):\n",
    "    list_urls=[]\n",
    "    for i in range (0,pages):\n",
    "        offset=i*20\n",
    "        page_url=url_flex.format(offset)\n",
    "        list_urls.append(page_url)\n",
    "    return list_urls\n",
    "\n",
    "test_urls=page_urls(school_url_flex, 2)\n",
    "test_urls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.ratemyprofessors.com/ShowRatings.jsp?tid=144',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=8086',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=8090',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=8154',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=8155',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=10897',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=16038',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=16519',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=16520',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=16521',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=16522',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=16529',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=17669',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=23963',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=23964',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=23971',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=23972',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=24985',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=24986',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=24987',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=24988',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=38413',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=48328',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=50114',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=53144',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=54555',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=55768',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=55769',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=59335',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=62919',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=62920',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=62921',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=62922',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=63540',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=68428',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=68431',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=69365',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=69869',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=74945',\n",
       " 'http://www.ratemyprofessors.com/ShowRatings.jsp?tid=75103']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate links for professsors. Give list of page_links, find out a list of links for professors\n",
    "\n",
    "\n",
    "def prof_urls(page_links, url_flex):\n",
    "    url_listing=[]\n",
    "    for link in page_links:\n",
    "        temp_response=requests.get(link)\n",
    "        temp_page=temp_response.text\n",
    "        temp_soup = BeautifulSoup(temp_page,\"lxml\")\n",
    "        for e in temp_soup.find_all('li',class_=\"listing PROFESSOR\"):  \n",
    "            temp= e.find('a')['href']\n",
    "            prof_url=prof_url_flex.format(temp)\n",
    "            url_listing.append(prof_url)\n",
    "    return url_listing\n",
    "                    \n",
    "    \n",
    "test_prof_urls=prof_urls(test_urls, prof_url_flex)\n",
    "test_prof_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John Griffith'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab professor name. Given school soup, retun string\n",
    "\n",
    "def get_name(prof_soup):\n",
    "    name=\"\"\n",
    "    if prof_soup.find_all(class_=\"profname\"):\n",
    "        for e in prof_soup.find_all(class_=\"profname\"):\n",
    "            name=e.find(class_=\"pfname\").text.strip()+\" \"+e.find(class_=\"plname\").text.strip()\n",
    "    return name\n",
    "\n",
    "get_name (prof_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the rating of professor. Given Soup, retun float\n",
    "\n",
    "def get_rating(prof_soup):\n",
    "    temp=\"\"\n",
    "    if prof_soup.find(class_=\"breakdown-container quality\"):\n",
    "        temp=prof_soup.find(class_=\"breakdown-container quality\")\n",
    "    if temp: \n",
    "        s=temp.find(class_='grade')\n",
    "        return float(s.text)\n",
    "    else: \n",
    "        return (0)\n",
    "            \n",
    "            \n",
    "get_rating(prof_soup)\n",
    "        \n",
    "# can be list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the level of difficulty of the professor. iven Soup, retun float\n",
    "\n",
    "def get_level_of_difficulty(prof_soup):\n",
    "    \n",
    "    if prof_soup.find(class_=\"breakdown-section difficulty\"):\n",
    "    \n",
    "        level_of_difficulty=prof_soup.find(class_=\"breakdown-section difficulty\").stripped_strings\n",
    "\n",
    "        return float(list (level_of_difficulty)[1])\n",
    "    else:\n",
    "        return (2.5) #return average difficulty level if no value\n",
    "\n",
    "get_level_of_difficulty(prof_soup)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab total number reviews\n",
    "\n",
    "def get_number_reviews(prof_soup):\n",
    "    \n",
    "    if prof_soup.find('div',class_=\"table-toggle rating-count active\"):\n",
    "        text=prof_soup.find('div',class_=\"table-toggle rating-count active\").text.strip()\n",
    "        num_students=int(re.findall(r'\\d+', text, re.I)[0])\n",
    "        return num_students\n",
    "    else:\n",
    "        return (0)\n",
    "\n",
    "get_number_reviews(prof_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accessible outside class',\n",
       " 'Amazing lectures',\n",
       " 'Beware of pop quizzes',\n",
       " 'Caring',\n",
       " 'Clear grading criteria',\n",
       " 'Extra credit',\n",
       " 'Get ready to read',\n",
       " 'Gives good feedback',\n",
       " 'Graded by few things',\n",
       " 'Group projects',\n",
       " 'Hilarious',\n",
       " 'Inspirational',\n",
       " 'Lecture heavy',\n",
       " 'Lots of homework',\n",
       " 'Participation matters',\n",
       " 'Respected',\n",
       " \"Skip class? you won't pass.\",\n",
       " 'So many papers',\n",
       " 'Test heavy',\n",
       " 'Tough grader']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all tags of professor\n",
    "tags_url=\"http://www.ratemyprofessors.com/AddRating.jsp?tid=9670\"\n",
    "tags_page=requests.get(tags_url).text\n",
    "tags_soup = BeautifulSoup(tags_page,\"lxml\")\n",
    "\n",
    "all_tags=[]\n",
    "for e in tags_soup.find_all('div', class_=\"scrollable\"):  #entire tag\n",
    "    for f in e.find_all('a',class_=''): #each tag was embed in tag-box-choosetags class\n",
    "        all_tags.append (f.text.strip().capitalize())\n",
    "all_tags.sort()\n",
    "all_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "all_tags=['Tough Grader',\n",
    " 'Gives good feedback',\n",
    " 'Respected',\n",
    " 'Get ready to read',\n",
    " 'Participation matters',\n",
    " \"Skip class? You won't pass.\",\n",
    " 'LOTS OF HOMEWORK',\n",
    " 'Inspirational',\n",
    " 'BEWARE OF POP QUIZZES',\n",
    " 'ACCESSIBLE OUTSIDE CLASS',\n",
    " 'SO MANY PAPERS',\n",
    " 'Clear grading criteria',\n",
    " 'Hilarious',\n",
    " 'TEST HEAVY',\n",
    " 'GRADED BY FEW THINGS',\n",
    " 'Amazing lectures',\n",
    " 'Caring',\n",
    " 'EXTRA CREDIT',\n",
    " 'GROUP PROJECTS',\n",
    " 'LECTURE HEAVY']\n",
    "'''\n",
    "# Grab the main tags of the professor. Given soup, return tags\n",
    "\n",
    "\n",
    "def get_tags(prof_soup):\n",
    "    list_of_tags=[]\n",
    "    dic={}\n",
    "    total_count=0\n",
    "    for e in prof_soup.find_all(class_=\"tag-box\"):  #entire tag\n",
    "        for f in e.find_all(class_='tag-box-choosetags'): #each tag was embed in tag-box-choosetags class\n",
    "            list_of_tags.append (f.text.strip())\n",
    "    \n",
    "    # sort result list for efficiency\n",
    "    list_of_tags.sort()\n",
    "    \n",
    "    #split text and add the count to each tag\n",
    "    for i in list_of_tags:\n",
    "        category=re.findall(r'[^\\(]*', i, re.I)[0].strip().capitalize()\n",
    "        count=int(re.findall(r'\\d', i, re.I)[0])\n",
    "        dic[category]=count\n",
    "        total_count+=count\n",
    "    \n",
    "    #normalize the count for each tag\n",
    "    for key in dic:\n",
    "        dic[key]=round(dic[key]/total_count,2)\n",
    "           \n",
    "    return dic\n",
    "    \n",
    "    \n",
    "    \n",
    "have=get_tags(prof_soup)\n",
    "have\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count and normalize all tags a professor has in review and return a list of counts\n",
    "# All tags is a lit and repreents entire listing of tags. Have_tags is a dictionary with normalized count of tags\n",
    "\n",
    "def tag_count(all_tags, have_tags):\n",
    "    dic={}\n",
    "    lis=[]\n",
    "    for key in all_tags:\n",
    "        dic[key]=0\n",
    "    \n",
    "    for key in have_tags:\n",
    "        if key in all_tags:\n",
    "            dic[key]=have_tags[key]\n",
    "    \n",
    "    for key in all_tags:\n",
    "        lis.append(dic[key])\n",
    "    \n",
    "    return lis\n",
    "\n",
    "tag_count(all_tags, have)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total professors: 5307 Pages: 266\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_prof=total_professors(school_soup)\n",
    "pages=page_of_listing(total_prof)\n",
    "\n",
    "result_urls=page_urls(school_url_flex, pages)\n",
    "\n",
    "print (\"Total professors: \"+str(total_prof), \"Pages: \"+str(pages))\n",
    "\n",
    "def scrape_data(urls):\n",
    "    data=[]\n",
    "    temp_page_links=prof_urls(urls, prof_url_flex)\n",
    "    for index, link2 in enumerate(temp_page_links):\n",
    "        # added statement to skip error as needed\n",
    "        try:         \n",
    "            temp=[]\n",
    "            temp_response=requests.get(link2)\n",
    "            temp_page=temp_response.text\n",
    "            temp_soup = BeautifulSoup(temp_page,\"lxml\")\n",
    "            temp_name=get_name (temp_soup)\n",
    "            temp_rating=get_rating(temp_soup)\n",
    "            temp_difficulty=get_level_of_difficulty(temp_soup)\n",
    "            temp_numbers_reviews=get_number_reviews(temp_soup)\n",
    "            have_tags=get_tags(temp_soup) \n",
    "            temp_tags=tag_count(all_tags, have_tags)\n",
    "\n",
    "            temp.extend([temp_name, temp_rating, temp_difficulty,temp_numbers_reviews])\n",
    "            temp.extend(temp_tags)\n",
    "\n",
    "            print(str(index)+\", \",end=\"\") # count the instance. print on same line\n",
    "            data.append(temp)\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            continue\n",
    "    return data\n",
    "\n",
    "\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e9115e72e426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpklfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpklfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/xzhou/github/project_files/project_luther/professor_data_uf.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e9115e72e426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpklfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscrape_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpklfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-b52af3dbeb48>\u001b[0m in \u001b[0;36mscrape_data\u001b[0;34m(urls)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscrape_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtemp_page_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprof_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprof_url_flex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_page_links\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# added statement to skip error as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-c6882c84ff5b>\u001b[0m in \u001b[0;36mprof_urls\u001b[0;34m(page_links, url_flex)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtemp_response\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtemp_page\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtemp_soup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_page\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_soup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'li'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"listing PROFESSOR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mParserRejectedMarkup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/builder/_lxml.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParserError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mParserRejectedMarkup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.close\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.close\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/etree.pyx\u001b[0m in \u001b[0;36mlxml.etree._ExceptionContext._raise_if_stored\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/saxparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._handleSaxTargetStartNoNs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/saxparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._callTargetSaxStart\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._PythonSaxParserTarget._handleSaxStart\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/builder/_lxml.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, name, attrs, nsmap)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getNsTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mnsprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefix_for_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prefix_for_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[0;34m(self, name, namespace, nsprefix, attrs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         tag = Tag(self, self.builder, name, namespace, nsprefix, attrs,\n\u001b[0;32m--> 465\u001b[0;31m                   self.currentTag, self._most_recent_element)\n\u001b[0m\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parser, builder, name, namespace, prefix, attrs, parent, previous, is_xml)\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuilder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdata_list_attributes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                 attrs = builder._replace_cdata_list_attribute_values(\n\u001b[0;32m--> 842\u001b[0;31m                     self.name, attrs)\n\u001b[0m\u001b[1;32m    843\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                 \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/builder/__init__.py\u001b[0m in \u001b[0;36m_replace_cdata_list_attribute_values\u001b[0;34m(self, tag_name, attrs)\u001b[0m\n\u001b[1;32m    161\u001b[0m             tag_specific = self.cdata_list_attributes.get(\n\u001b[1;32m    162\u001b[0m                 tag_name.lower(), None)\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muniversal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtag_specific\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtag_specific\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# We have a \"class\"-type attribute whose string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#save to pick for efficiency\n",
    "\n",
    "import pickle\n",
    "\n",
    "filename = '/Users/xzhou/github/project_files/project_luther/professor_data_uf.pkl' #4000 records\n",
    "\n",
    "try:\n",
    "    with open(filename,'rb') as pklfile:\n",
    "        df = pickle.load(pklfile)\n",
    "except:\n",
    "    result=scrape_data(result_urls)\n",
    "    df=pd.DataFrame(result)\n",
    "    with open(filename,'wb') as pklfile:\n",
    "        df = pickle.dump(df, pklfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(df, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "filename2 = '/Users/xzhou/github/project_files/project_luther/professor_data_uf2.pkl' #4000 records\n",
    "\n",
    "try:\n",
    "    with open(filename2,'rb') as pklfile:\n",
    "        df2 = pickle.load(pklfile)\n",
    "\n",
    "except:\n",
    "    with open(filename2,'wb') as pklfile:\n",
    "        df2 = pickle.dump(df, pklfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
